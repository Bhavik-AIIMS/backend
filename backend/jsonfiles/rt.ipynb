{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "rt.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS04bS_xzt2l",
        "colab_type": "code",
        "outputId": "948fd03c-767b-4fb2-fa52-8abb76fa1c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=51916b011537cfa76dd77976bd6f88865101df1260ac95d07121b336ff428e1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg4B7WwDzp_9",
        "colab_type": "code",
        "outputId": "a6880425-5dfb-4796-e153-732c8a6fef1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from subprocess import call\n",
        "from scipy.stats.distributions import gamma\n",
        "import json \n",
        "import wget\n",
        "import os\n",
        "import os.path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7FrMFo_0gK0",
        "colab_type": "code",
        "outputId": "14fb9b8c-17d4-48cb-b345-c5d09acc88a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "if os.path.exists(os.getcwd()+\"\\\\national.json\"):\n",
        "    os.remove(os.getcwd()+\"\\\\national.json\")\n",
        "wget.download('https://api.covid19india.org/data.json', os.getcwd()+\"//national.json\")\n",
        "\n",
        "if os.path.exists(os.getcwd()+\"\\\\states.json\"):\n",
        "    os.remove(os.getcwd()+\"\\\\states.json\")\n",
        "wget.download('https://api.covid19india.org/states_daily.json', os.getcwd()+\"//states.json\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive//states (1).json'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onP6Jq5RzqAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pooled_SD(sds,means):\n",
        "    return np.sqrt((np.sum(sds**2,axis=0)+np.sum(means-np.mean(means,axis=0)))/sds.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "colNKV4kzqAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_data = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w93pDNZ4zqAV",
        "colab_type": "text"
      },
      "source": [
        "### Calculation for Rt (India - No Import Adjustment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWN18py3zqAW",
        "colab_type": "code",
        "outputId": "df68c600-4fc5-4135-ab47-4736a06df965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "source": [
        "dates = np.array([pd.to_datetime(i['date']+\"2020\") for i in json.load(open('national.json',))['cases_time_series']])\n",
        "confirmed = np.array([int(i['dailyconfirmed'])for i in json.load(open('national.json',))['cases_time_series']])\n",
        "\n",
        "confirmed = confirmed[dates>=pd.to_datetime(\"03/04/20\")]\n",
        "dates = dates[dates>=pd.to_datetime(\"03/04/20\")]\n",
        "\n",
        "real_data = confirmed\n",
        "\n",
        "rt = []\n",
        "dats = []\n",
        "for n in range(2):\n",
        "    print(\"Iteration: \",n+1,end='\\r')\n",
        "    dataset = np.copy(real_data)\n",
        "    G = gamma(3.325+0.616*np.random.normal(),0.979+0.195*np.random.normal())\n",
        "    for i in range(len(dataset)):\n",
        "        send_back = np.clip(np.round(G.rvs(np.max([0,int(dataset[i])]))),0,10)\n",
        "        send_back = send_back[i-send_back>=0]\n",
        "        dataset[i] = 0\n",
        "        for j in np.unique(np.int32(send_back)):\n",
        "            dataset[i-j] += np.sum(send_back==j)\n",
        "    dataset[::-1] = dataset[::-1]+np.random.negative_binomial(n=dataset[::-1]+1,p=G.cdf(np.arange(len(dataset))),size=len(dataset)) \n",
        "    df = pd.DataFrame()\n",
        "    df['active'] = dataset[:-3]\n",
        "    df['date'] = dates[:-3]\n",
        "    df.to_csv('dataset.csv',index=False)\n",
        "    call(['RScript.exe','scripts/Rt_analysis.R'])\n",
        "    rt.append(pd.read_csv('rtoutput.csv'))\n",
        "    dats.append(dataset[:-3])\n",
        "\n",
        "means = np.array([x[\"Mean(R)\"].values for x in rt])\n",
        "sds = np.array([x[\"Std(R)\"].values for x in rt])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  1\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-eb96801515b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RScript.exe'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'scripts/Rt_analysis.R'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rtoutput.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \"\"\"\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    727\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1362\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'RScript.exe': 'RScript.exe'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsTogwOJzqAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stindex = 2+5-1\n",
        "india = {\n",
        "        'dates':list(pd.Series(dates)[stindex:stindex+means.shape[1]].dt.strftime('%m-%d-%Y')),\n",
        "        'rt_point':list(means.mean(axis=0)),\n",
        "        'rt_sd':list(pooled_SD(sds,means)),\n",
        "        'rt_l95':list(means.mean(axis=0)-1.95996*pooled_SD(sds,means)),\n",
        "        'rt_u95':list(means.mean(axis=0)+1.95996*pooled_SD(sds,means)),\n",
        "        'rt_l50':list(means.mean(axis=0)-0.67449*pooled_SD(sds,means)),\n",
        "        'rt_u50':list(means.mean(axis=0)+0.67449*pooled_SD(sds,means)),\n",
        "        'cases_mean':list(np.mean(dats,axis=0)),\n",
        "        'cases_sd':list(np.std(dats,axis=0)),\n",
        "        'cases_dates':list(pd.Series(dates)[:-3].dt.strftime('%m-%d-%Y'))\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMAg9Yo5zqAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_data['IN'] = india"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR9UQk46zqAr",
        "colab_type": "text"
      },
      "source": [
        "### State Level Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9640HhV4zqAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states = list(filter(lambda v:len(v)<3,list(json.load(open('states.json',))['states_daily'][0].keys())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXFb8gevzqAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dates = np.array([pd.to_datetime(i['date']) for i in filter(lambda v: v['status'] == 'Confirmed',json.load(open('states.json',))['states_daily'])])\n",
        "data = pd.DataFrame()\n",
        "for st in states:\n",
        "    data[st] = np.array([i[st] for i in filter(lambda v: v['status'] == 'Confirmed',json.load(open('states.json',))['states_daily'])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoileJ5bzqA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.replace(r'^\\s*$', np.NaN, regex=True).fillna(0)\n",
        "data = data.astype(np.int32)\n",
        "data['date'] = dates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "HuUH522NzqA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_id = {\"kl\":\"Kerala\",\n",
        "  \"mh\":\"Maharashtra\",\n",
        "  \"gj\":\"Gujarat\",\n",
        "  \"dl\":\"Delhi\",\n",
        "  \"rj\":\"Rajasthan\",\n",
        "  \"tn\":\"Tamil Nadu\",\n",
        "  \"mp\":\"Madhya Pradesh\",\n",
        "  \"up\":\"Uttar Pradesh\",\n",
        "  \"tg\":\"Telangana\",\n",
        "  \"ap\":\"Andhra Pradesh\",\n",
        "  \"ka\":\"Karnataka\",\n",
        "  \"wb\":\"West Bengal\",\n",
        "  \"jk\":\"Jammu and Kashmir\",\n",
        "  \"hr\":\"Haryana\",\n",
        "  \"pb\":\"Punjab\",\n",
        "  \"br\":\"Bihar\",\n",
        "  \"or\":\"Odisha\",\n",
        "  \"jh\":\"Jharkand\",\n",
        "  \"ut\":\"Uttarakhand\",\n",
        "  \"hp\":\"Himachal Pradesh\",\n",
        "  \"ct\":\"Chhattisgarh\",\n",
        "  \"as\":\"Assam\",\n",
        "  \"ch\":\"Chandigarh\",\n",
        "  \"la\":\"Ladakh\",\n",
        "  \"an\":\"Andaman and Nicobar Islands\",\n",
        "  \"ml\":\"Meghalaya\",\n",
        "  \"ga\":\"Goa\",\n",
        "  \"py\":\"Puducherry\",\n",
        "  \"mn\":\"Manipur\",\n",
        "  \"tr\":\"Tripura\",\n",
        "  \"ar\":\"Arunachal Pradesh\",\n",
        "  \"mz\":\"Mizoram\" , }\n",
        "\n",
        "for state in state_id.keys():\n",
        "    print(\"\\n\",state)\n",
        "    boots = 100\n",
        "    real_data = data[state].values\n",
        "    df = pd.DataFrame()\n",
        "    df['active'] = real_data\n",
        "    df.to_csv('dataset.csv',index=False)\n",
        "    rt = []\n",
        "    dats = []\n",
        "    for n in range(boots):\n",
        "        print(\"Iteration: \",n+1,end='\\r')\n",
        "        G = gamma(3.325+0.616*np.random.normal(),0.979+0.195*np.random.normal())\n",
        "        dataset = np.copy(real_data)\n",
        "        for i in range(len(dataset)):\n",
        "            send_back = np.clip(np.round(G.rvs(np.max([0,int(dataset[i])]))),0,10)\n",
        "            send_back = send_back[i-send_back>=0]\n",
        "            dataset[i] = 0\n",
        "            for j in np.unique(np.int32(send_back)):\n",
        "                dataset[i-j] += np.sum(send_back==j)\n",
        "        dataset[::-1] = dataset[::-1]+np.random.negative_binomial(n=dataset[::-1]+1,p=G.cdf(np.arange(len(dataset))),size=len(dataset)) \n",
        "        df = pd.DataFrame()\n",
        "        df['active'] = dataset[:-3]\n",
        "        df['date'] = dates[:-3]\n",
        "        dats.append(dataset[:-3])\n",
        "        df.to_csv('dataset.csv',index=False)\n",
        "        call(['RScript.exe','scripts/Rt_analysis.R'])\n",
        "        rt.append(pd.read_csv('rtoutput.csv'))\n",
        "\n",
        "    means = np.array([x[\"Mean(R)\"].values for x in rt])\n",
        "    sds = np.array([x[\"Std(R)\"].values for x in rt])\n",
        "    dat_means = np.mean(dats,axis=0)\n",
        "    dat_sds = np.std(dats,axis=0)\n",
        "    \n",
        "    stindex = 2+5-1\n",
        "    temp = {\n",
        "            'dates':list(pd.Series(dates)[stindex:stindex+means.shape[1]].dt.strftime('%m-%d-%Y')),\n",
        "            'rt_point':list(means.mean(axis=0)),\n",
        "            'rt_sd':list(pooled_SD(sds,means)),\n",
        "            'rt_l95':list(means.mean(axis=0)-1.95996*pooled_SD(sds,means)),\n",
        "            'rt_u95':list(means.mean(axis=0)+1.95996*pooled_SD(sds,means)),\n",
        "            'rt_l50':list(means.mean(axis=0)-0.67449*pooled_SD(sds,means)),\n",
        "            'rt_u50':list(means.mean(axis=0)+0.67449*pooled_SD(sds,means)),\n",
        "            'cases_mean':list(np.mean(dats,axis=0)),\n",
        "            'cases_sd':list(np.std(dats,axis=0)),\n",
        "            'cases_dates':list(pd.Series(dates)[:-3].dt.strftime('%m-%d-%Y'))\n",
        "            }\n",
        "    json_data[state] = temp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbOg8nEFzqBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data.json', 'w') as outfile:\n",
        "    json.dump(json_data, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}